\chapter{Introduction}
\label{CHAP_FIRST}
\centerline{\rule{149mm}{.02in}}
\vspace{2cm}
\section{Project Aim}
Large scale data processing is an emerging trend in Computing, with benefits to both academia and industry. The aim of this project is to investigate the challenges of large scale parallel data processing, discuss the benefits of Cloud Computing and investigate how the efficiency of large scale data processing may be improved. 

This project will aim to provide a reasoned and objective evaluation of the efficiency of data processing techniques, whilst comparing current state of the art tools and technologies with newer research in the field. 

Specifically, the data processing tools Hadoop and Stratosphere will be compared, allowing comparison of the individual tools, and a wider discussion of the pros and cons of the MapReduce and PACT programming paradigms. 

\subsection{Motivation}
In recent times the amount of data generated and stored by industry and academia has grown considerably. This has led to a series of tools being developed to make it feasible to analyse large amounts of information and reach meaningful conclusions. In particular the MapReduce paradigm (and the Hadoop implementation) have emerged as the prominent tools for processing large amounts of data in parallel.

There are several issues with MapReduce. The most significant of these is that it is not possible to represent some tasks in such a way that it is efficient to compute the result whilst being limited to just the Map and Reduce operations. This makes it unreasonable to use Hadoop for a whole category of problems. 

Clearly there is a need for a more flexible data processing framework which can solve a wider range of problems. Fortunately, MapReduce is not the only paradigm for this type of problem. The motivation behind this piece of work is to show that an alternative programming framework (PACT) can provide a reasonable way of solving tasks in the category of problems that MapReduce cannot, and to determine whether an alternative data processing paradigm and framework can remove some of the restrictions on large scale data processing. 

\subsection{Research Questions}
The project aims to answer the following questions:

\begin{itemize}
	\item Does PACT overcome the inherent disadvantages of the MapReduce paradigm?
	\item How well does Stratosphere perform MapReduce tasks?
	\item How do Hadoop and Stratosphere perform in a highly elastic Cloud Computing environment?
\end{itemize}  

\section{Objectives}
The objectives of the project are:

\begin{itemize}
	\item Investigate Cloud Computing, Big Data and other relevant background trends
	\item Design a series of experiments to determine the efficiency of data processing technologies
	\item Implement the experiments for both Hadoop and Stratosphere
	\item Evaluate the experiment results to draw meaningful conclusions to the research questions
\end{itemize}

\section{Methodology}
The project will be broken into three main phases. The order to the phases provides a structured approach to the project, and completion of each phase ensures the project is completed in a methodical manner. The \textbf{Background Research} section will provide a comprehensive literature review to provide context to the project. This will be followed by a phase of \textbf{Experimentation}, which will aim to test the necessary factors of Hadoop and Stratosphere to answer the research questions. Finally, the \textbf{Evaluation} phase will evaluate the results of the experiments and the project as a whole.

The phases of the project will be performed according to Agile principles. Work will be carried out in weekly sprints, with clearly defined targets for each sprint. Supervisor meetings will be used as an opportunity to reflect on the achievements and shortcomings of the previous week, and to set targets for the upcoming sprint.

\subsection{Background Research}
The background research will aim to provide context for the project by surveying the current research landscape. It will summarise the fundamental concepts underlying the project and give a strong theoretical foundation for the rest of the project.

The first section of the background research will focus on Cloud Computing. It will explore the principles of the cloud, the service and deployment models and the technologies which make the cloud possible. It will also look at the unique advantages that the cloud provides in data processing scenarios.

The second segment of the background research will look in to Big Data and what challenges it introduces. An overview will be given of tools and techniques which have been developed to process Big Data, including Hadoop and Stratosphere.

\subsection{Experimentation}
Experiments will be designed to test the efficiency of data processing tools in relevant situations. This will require identifying relevant areas of interest, and deriving scenarios which will test the efficiency of Hadoop and Stratosphere. The experiments should be designed to take into account the various different problems that data processing tools are required to solve and to provide findings for the research questions.

As part of the experiment design, a hypothesis will be produced.

The experiments will be implemented and executed, in order to provide results which can be used to answer the research questions.

\subsection{Evaluation}
The project can be evaluated on various factors.

A technical evaluation will be carried out to analyse the results of the experiments. It will compare the efficiency of Hadoop and Stratosphere, referring to data obtained in the experimentation phase. The results will be compared to existing research (obtained during the background research) and the hypothesis, and any discrepancies will be discussed. 

An evaluation will also be carried out to determine whether the aims and objectives of the project have been met. This will involve determining whether the research questions have been answered in a satisfactory manner, and determining the relevance of the project in regards to existing literature and how it contributes to the research landscape. Any future scope for research will be identified. 

The methodology and management of the project will also be evaluated to identify areas of improvement in project management.

\section{Requirements}
The projects success will be judged on whether it meets a set of requirements. Requirements will be broken into 2 categories. Minimum requirements are essential for the success of the project. Failure to meet any of the minimum requirements would seriously compromise the project, and would make it unlikely to qualify for a pass grade. There are also various extended requirements. These requirements can be seen as `stretch goals'. They are not essential for the project, but will contribute considerably to the end product.

\subsection{Minimum Requirements}
By meeting the minimum requirements, it should be possible to replicate the results in existing literature \cite{warneke2011exploiting}. 

\begin{itemize}
	\item Install Hadoop

	Installing Hadoop is a necessary part of the project as it must be used to run data processing experiments. At a minimum, Hadoop should be installed on the University of Leeds School of Computing Cloud Testbed. 

	\item Install Stratosphere

	Installing Stratosphere is a necessary part of the project so experiments can be run, and the results compared with Hadoop. At a minimum, Stratosphere should be installed on the University of Leeds School of Computing Cloud Testbed. 
	
	\item Run a MapReduce processing task

	There are various basic MapReduce tasks which are provided as examples for both Stratosphere and Hadoop. Common examples are Word Counting and the Terasort benchmark. The example code provided could be executed against the same dataset to provide a basic comparison of the performance of Hadoop and Stratosphere in a MapReduce situation.

	\item Run a non-MapReduce processing task

	There are various pieces of example code for Stratosphere which demonstrate non-MapReduce processes such as K-Means clustering. There are also various libraries and frameworks for Hadoop which provide implementations of algorithms such as K-Means. These implementations can be compared in order to determine whether PACT overcomes the issues with MapReduce.

	\item Run an experiment on a different cluster size

	In order to determine how scalable the solutions are, an experiment must be run on more than one cluster size. As a minimum requirement, the MapReduce benchmark (e.g. Word Count, Terasort) could be run on 2 and 4 machines for each processing technology, with the results compared for scalability.
\end{itemize}

\subsection{Extended Requirements}
The extended requirements provide extensions to the project which constitute work that furthers the existing research.

\begin{itemize}
	\item Real-world problem

	In addition to running a basic MapReduce and non-MapReduce problem, a `real-world' scenario could be chosen. This would reflect the use of data processing tools in a more natural way, rather than relying on synthetic benchmarks. There are various datasets made publicly available \cite{publicAmazonData}, and these could be analysed using both of the data processing tools with their execution times compared. An example of the type of problem which may be relevant is the 1000 genome project \cite{genomeData}.

	In addition to testing the performance of Hadoop and Stratosphere in a less artificial environment, this extended requirement will also require new code to be developed to run on the processing technologies, rather than using existing example code.

	\item Scale all experiments

	Rather than just scaling one experiment across 2 different cluster sizes, all experiments could be ran across different cluster sizes to provide a more comprehensive measure of scalability. Additionally, the cluster size could vary to a larger extent. Rather than running experiments on 2 cluster sizes, they could be executed on a larger range of machines.

	\item Public Cloud

	As a minimum requirement, the clusters will be built on the University of Leeds School of Computing Cloud Testbed. An extension would be to run experiments using a public Infrastructure as a Cloud service such as Amazon EC2 or Windows Azure. 
\end{itemize}

\section{Schedule}
The project schedule will be created around a set of fixed milestones in the project process. Work will be allocated in weekly sprints to ensure that the relevant work is completed in time for each milestone. Work will be prioritised so that scope can be cut to meet a milestone if required.

\subsection{Project Tasks}
There are various high level tasks throughout the project which must be carried out in order to complete the research. Whilst the Project Milestones are fairly generic and apply to all Final Year Projects, the tasks taken to achieve these milestones are specific to this project.

\begin{enumerate}
	\item Determine Aims

	The project aims will state what will be achieved in the project. This is a necessary prerequisite for choosing the experiments. 

	\item Choose Experiments

	Experiments will be chosen based on their relevancy to the project aims, in order to meet the objectives. The number, type and reason for experiments need to be determined.

	\item Design/Prototype Experiments

	The background research indicates that it is possible to test Hadoop and Stratosphere processing jobs `locally' (without requiring a full cluster). This will be useful in learning the development tools and technologies. It will also be an opportunity to begin to implement some of the code required for the experiments, and verify it on a small synthetic dataset. This process should be faster than running a full experiment, and will validate that the code is correct.

	The prototyping phase can therefore be used as an opportunity to design the experiments which will be executed on the full cluster, as at this point the necessary information should be available to determine what is feasible.

	\item Configure Cluster

	The Hadoop and Stratosphere clusters will need to be configured on the School of Computing Cloud Testbed, and also potentially on a public cloud. This is a necessary step in running the experiments.

	\item Acquire Data

	A real dataset will need to be acquired for use in the experiments. Where the prototypes will run on smaller, synthetic datasets, the real experiments will need a full dataset to analyse. The data will be different depending on the experiment. In some situations, data can be generated (for example, if K-Means clustering is used, data could simply be generated to the required size) whereas in other scenarios data will need to be acquired from an alternative source. If the additional requirement for a `real-world problem' is met, this will require an associated real-world data source.

	\item Implement Experiments

	The chosen experiments should be implemented for all platforms. Whilst it can be expected that some of the experiments would have been implemented during the prototyping phase, this step will be necessary to ensure that the prototype code is suitable for the cluster and that it can process the data which has been acquired. It will also provide an opportunity to implement any experiments which were designed but not developed during the prototyping phase.

	\item Run Experiments

	The experiments will be run across all platforms and technologies, and the results collected.

	\item Evaluate Data

	The data stemming from the experiments will be evaluated to reach meaningful conclusions relevant to the Aims \& Objectives.

\end{enumerate}

\subsection{Project Milestones}
There are a series of milestones which must be met throughout the project. This provides a framework for the project plan, as necessary tasks must be completed before the milestones.

\begin{enumerate}
	\item Submission of Aims \& Objectives

	The Aims \& Objectives of the project must be decided, which is crucial in setting the scope and direction for the rest of the project.

	\item Presentation to the Distributed Systems and Services Group

	The presentation to the Distributed Systems and Services group provides an opportunity to get early feedback on the project, and present much of what will be present in the mid year report. In order to present the project, a sufficient amount of content must be prepared. By this point a substantial amount of background research should have been carried out, and early ideas about experimental design should be formed.

	\item Mid Project Report

	The Mid Project Report is a chance to get feedback from the assessor about the direction and progress of the project. By this stage the background research should be completed, and should demonstrate that necessary steps have been taken to understand the problem. The Aims \& Objectives should be clearly defined, with a set of deliverables, a methodology, and a schedule. At this point experimental design will not have been completed, but the Mid-Year Report should give indications about the type of experiments that will be executed and why they were chosen. Finally, evidence of basic implementation should be shown, to demonstrate knowledge of the tools required for experiment implementation. 

	\item Progress Meeting

	The progress meeting occurs in the late stages of the project, so at this point most of the work should be completed. Experiments should have been implemented and performed, and code should be available for inspection.

	\item Final Report Submission
	
	The final report submission marks a point where all work on the project has to be complete. 
\end{enumerate}

\subsection{Original Schedule}
The original schedule was created at the start of the project, after the Aims \& Objectives had been created. At this stage it was left intentionally vague, as it was anticipated that more information would become available as the initial stages of the project were completed. For example, there is time allocated for Experiment Implementation and Additional Requirements, rather than actual individual experiments or work required to complete specific additional requirements.

\begin{figure}[H]
\centering
\begin{ganttchart}[
	vgrid,
	hgrid,
	]{1}{16}
	\gantttitle{Project Schedule (weeks)}{16} \\
	\gantttitlelist{1,...,16}{1} \\
	\ganttgroup{Background Research}{1}{6} \\
	\ganttbar{Aims \& Objectives}{1}{1} \\
	\ganttbar{Literature Review}{2}{4} \\
	\ganttmilestone{Presentation to Distributed Systems Group}{4} \\
	\ganttgroup{Experiment Implementation}{6}{13} \\
	\ganttbar{Experiment Prototypes}{3}{5} \\
	\ganttmilestone{Mid Project Report}{6} \\
	\ganttbar{Configure Cluster}{6}{7} \\
	\ganttbar{Experiment Implementation}{7}{11} \\
	\ganttbar{Additional Requirements}{11}{13} \\
	\ganttmilestone{Progress Meeting}{13} \\
	\ganttgroup{Evaluation}{13}{15} \\
	\ganttbar{Evaluation}{13}{14} \\
	\ganttbar{Project Write-up}{14}{16} \\
	\ganttmilestone{Deadline}{16}
\end{ganttchart}
\caption{Gantt Chart of Original Project Schedule}
\label{originalGantt}
\end{figure}

\subsection{Modified Schedule}
The modified schedule was created after the presentation to the distributed systems research group. At this point a sufficient amount of background research had been completed to complete a more comprehensive project plan. At this point the Project Tasks had been determined. 

\begin{figure}[H]
\centering
\begin{ganttchart}[
	vgrid,
	hgrid,
	y unit chart=.9cm
	]{1}{16}
	\gantttitle{Project Schedule (weeks)}{16} \\
	\gantttitlelist{1,...,16}{1} \\
	\ganttbar{Aims \& Objectives}{1}{1} \\
	\ganttbar{Literature Review}{2}{4} \\
	\ganttmilestone{Choose Experiments}{4} \\
	\ganttbar{Acquire Data}{4}{5} \\
	\ganttbar{Prototype Locally}{4}{5} \\
	\ganttbar{Write Mid Project Report}{5}{6} \\
	\ganttmilestone{Mid Project Report}{6} \\
	\ganttbar{Configure Cluster}{6}{7} \\
	\ganttmilestone{Cluster Prepared}{7} \\
	\ganttbar{Run MapReduce Experiment}{7}{8} \\
	\ganttbar{Run Non-MapReduce Experiment}{8}{10} \\
	\ganttbar{Run Real World Experiment}{10}{12} \\
	\ganttbar{Initial Evaluation}{12}{13} \\
	\ganttmilestone{Progress Meeting}{13} \\
	\ganttbar{Further Evaluation}{13}{14} \\
	\ganttbar{Project Write-up}{14}{16} \\
	\ganttmilestone{Deadline}{16}
\end{ganttchart}
\caption{Gantt Chart of Modified Project Schedule}
\label{modifiedGantt}
\end{figure}

\section{Deliverables}
The project will deliver the following:

\begin{enumerate}
	\item An evaluation of the efficiency of Hadoop and Stratosphere in various data processing situations
	\item Code for experiments, designed to test the efficiency of Hadoop and Stratosphere
	\item If the extended requirements are met, a contribution to the research landscape by considering novel problems, evaluating the scalability of the data processing tools and comparing their implementation in public and private cloud environments.
\end{enumerate}